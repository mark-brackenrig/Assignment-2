method = "gbm", trControl = ctrl, tuneGrid = grid[3,])
data
data <- data
datasets::AirPassengers
??datasets::
??datasets
data <- bordeaux
library(ade4)
data <- bordeaux
data <- data(bordeaux)
data <- iris
data$vs <- as.factor(data$vs)
data <- iris
gbmTrain <- data[sample(nrow(data), round(nrow(data)*0.9),  replace = F),]
#this creates the tuning grid, ensure you name the features the same as the hyper parameters
grid <- expand.grid(n.trees = c(1000,1500), interaction.depth=c(3:5), shrinkage=c(0.05,0.1,0.2), n.minobsinnode=c(20))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
###Optimise for the Testing Set
set.seed(124)
library(caret)
GBMModel <- train(Species~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid[3,])
summary(GBMModel)
print(GBMModel)
grid[3,]
GBMModel <- train(Species~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid)
GBMModel <- train(Species~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid)
View(grid)
grid <- expand.grid(n.trees = c(1000), interaction.depth=c(3:4), shrinkage=c(0.05,0.1), n.minobsinnode=c(20))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
###Optimise for the Testing Set
set.seed(124)
library(caret)
GBMModel <- train(Species~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid)
print(GBMModel)
?gbm
table(gbmTrain$Species)
confusionMatrix(GBMModel)
library(glmnet)
lassofit <- cv.glmnet(Species~.)
training <- model.matrix(~ ., data))
training <- model.matrix(~ ., data)
training <- model.matrix(~ ., subset(data, select = -c("Species")))
training <- model.matrix(~ ., subset(data, select = c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")))
fit <- cv.glmnet(x = training, y = data$Species, alpha = 1)
fit <- cv.glmnet(x = training, y = data$Petal.width, alpha = 1)
training <- model.matrix(~ ., subset(data, select = c("Sepal.Length","Sepal.Width","Petal.Length")))
fit <- cv.glmnet(x = training, y = data$Petal.width, alpha = 1)
fit <- cv.glmnet(x = training, y = data$Petal.Width, alpha = 1)
?cv.glmnet
fit
summary(fit)
plot(fit)
print(fit)
fit$lambda.min
fit$lambda.1se
coef(fit, s = fit$lambda.min)
fit$lambda.min
fit$lambda.1se
coef(fit, s = fit$lambda.1se)
?cv.glmnet
fit <- cv.glmnet(x = training, y = data$Petal.Width, alpha = 0)
print(fit)
coef(fit, s = fit$lambda.min)
??svm
svmmodel <- train(Species~.,data = gbmTrain,
method = "lssvmRadial", trControl = ctrl)
svmmodel <- train(Species~.,data = gbmTrain,
method = "lssvmRadial")
print(svmmodel)
grid <- expand.grid(size = c(2,3,4), decay = (0.05, 0.1, 0.15))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
grid <- expand.grid(size = c(2,3,4), decay = c(0.05, 0.1, 0.15))
nnetmodel <- train(Species~.,data = data,
method = "nnet",trControl = ctrl, tuneGrid = grid)
print(nnetmodel)
grid <- expand.grid(size = c(2,3,4,5), decay = c(0.01,0.05, 0.1, 0.15))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
nnetmodel <- train(Species~.,data = data,
method = "nnet",trControl = ctrl, tuneGrid = grid)
print(nnetmodel)
?nnet
install.packages("RJDBC")
library(RJDBC)
install.packages("rJava")
library(RJDBC)
library(installr)
updater()
experiment <- expand.grid(
Withdraw = c("Yes", "No"),
Revers = c("Yes", "No"),
Health = c("Yes", "No"),
Profit = c("Yes", "No"),
Deferred = c("Yes", "No")
)
design<-caFactorialDesign(data=experiment,type="orthogonal")
library(conjoint)
design<-caFactorialDesign(data=experiment,type="orthogonal")
View(design)
design2<-caFactorialDesign(data=experiment,type="orthogonal",cards = 2)
View(design2)
?caFactorialDesign
print(cor(caEncodedDesign(design)))
install.packages(c("nycflights13", "gapminder", "Lahman"))
ggplot(data = mpg)
library(tidyverse)
ggplot(data = mpg)
install.packages("tidyverse")
library(tidyverse)
library(installr)
shiny::runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
shiny::runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
library(boot)
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
install.packages("shinythemes")
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
700*1.2
install.packages("austres")
install.packages("astsa")
Q <- factor(cycle(austres)) # split into quarter factors
trend <- time(austres) - 1980 # center the time to make the results look better using 1980 as midway in the whole dataset
reg <- lm(log(austres) ~ 0 + trend + Q, na.action=NULL) # run the regression without intercept
summary(reg)
table(trend)
plot(trend)
plot(log(austres))
plot(Q)
plot(time(austres))
time(austres)
austres
plotaustres
plot(austres)
library(conjoint)
library(AlgDesign)
library(compiler)
??compiler
f <- function() {
a = 5
b = 6
a+b
}
f
f()
compile(f)
e <- compile(f)
e
fc(2)
f <- function(x) x+1
fc <- cmpfun(f)
fc(2)
View(fc)
oldJIT <- enableJIT(0)
# a simple example
f <- function(x) x+1
fc <- cmpfun(f)
fc(2)
e <- compile(f)
e()
e
?compile
eval(e)
f <- function() {
a = 5
b = 6
a+b
}
e <- compile(f)
eval(e)
e
e()
eval(e)
disassemble(e)
write(e, "e.dll")
write(e, "e")
cmpfile(e)
e
f <- eval(e)
f
f()
g <- eval(e)
g()
save(e)
save(e, file = "test")
save(e, file = "test.class")
e
mode(e)
model1<-lm(BMI~height + mass, data =filter(newStarwars,BMI<440))
newStarwars
data
data()
data(package = .packages(all.available = T))
library(tidyverse)
newStarwars
model1<-lm(BMI~height + mass, data =filter(newStarwars,BMI<440))
library(dplyr)
model1<-lm(BMI~height + mass, data =filter(newStarwars,BMI<440))
starwars %>% mutate(BMI:=mass/((height/100)^2)) -> newStarwars
ggplot(data = newStarwars, mapping = aes(x = mass, y = BMI)) + geom_point()
?filter
?select
model1<-lm(BMI~height + mass, data =filter(newStarwars,BMI<440))
model1
summary(model1)
predict(model1, data.frame(height = 60, mass = 35))
shiny::runApp('planner-consultation-tool')
titanicData <- read_csv("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv")
titanicData$id <- 1:nrow(titanicData)   # adding an id number to each row for tracking
titanic.train <- titanicData %>% dplyr::sample_frac(.75)
titanic.test  <- dplyr::anti_join(titanicData, titanic.train, by = 'id')
missmap(titanic.train, main = "Missing values vs observed")
library(Amelia)
install.packages("Amelia")
glm1 = glm(survived ~ pclass + sex, family=binomial(logit), data = titanic.train)
summary(glm1)
plot(glm1)
eq = function(x){1/(1+exp(-x))}
ggplot(data.frame(x=c(-20, 20)), aes(x=x)) + stat_function(fun=eq, geom="line") + xlab("X") + ylab("P(Y|X)")
predict(glm1,newdata = titanic.test[1,])
(prediction<-predict(glm1,newdata = data.frame(sex="male",pclass=3),type="response"))
(predicted<-predict(glm1,titanic.test,type='response'))
prediction <- ifelse(predicted > 0.5, 1, 0)
confusion  <- table(titanic.test$survived, prediction)
confusion
glm2 = glm(survived ~. , family = "binomial", data = titanic.train)
glm2 = glm(survived ~. , family = binomial(logit), data = titanic.train)
confusion
gpaData<- read_delim("http://onlinestatbook.com/2/case_studies/data/sat.txt",delim=" ")
mlm1 <- lm(univ_GPA ~ high_GPA + math_SAT + verb_SAT,data=gpaData)
summary(mlm1)
cor(gpaData)
awardData <- read_csv("https://stats.idre.ucla.edu/stat/data/poisson_sim.csv")
glimpse(awardData)
library(magrittr)
awardData %<>% mutate(id=as.factor(id),prog=as.factor(prog))
glimpse(awardData)
table(awardData$num_awards)
ggplot(awardData)+geom_bar(aes(x=num_awards))
glm.awards<-glm(num_awards~prog+math, awardData, family=poisson)
summary(glm.awards)
glm.awards<-glm(num_awards~prog+math, awardData, family=poisson)
glm1 = glm(survived ~ pclass + sex, family=binomial(logit), data = titanic.train)
plot(glm1$fitted.values)
hist(glm1$fitted.values)
summary(glm.awards)
hist(glm.awards$residuals)
hist(log(glm.awards$residuals))
hist(glm.awards$residuals)
summary(glm.awards$residuals)
summary(glm.awards$residuals+1)
sd(glm.awards$residuals+1)
sd(glm.awards$residuals)
predict(glm.awards,newdata = data.frame(prog=factor(2),math=54),type="response")
install.packages("AER")
??pir
?pir
library(jsonlite)
library(rjson)
test <- fromJSON("https://data.gov.au/api/3/action/package_show?id=70c2b2fe-2a32-450e-98dc-453fe4a02aae")
test <- fromJSON(file = "https://data.gov.au/api/3/action/package_show?id=70c2b2fe-2a32-450e-98dc-453fe4a02aae")
test
test$result
fromJSON(test$result)
library(XML)
test2 <- xml(x = "https://data.gov.au/dataset/location-of-centrelink-offices/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2
??xml
library(rvest)
test2 <- xml(x = "https://data.gov.au/dataset/location-of-centrelink-offices/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2 <- read_xml(x = "https://data.gov.au/dataset/location-of-centrelink-offices/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test$result
unlist(test)
test2 <- as.data.frame(unlist(test))
View(test2)
library(rvest)
test2 <- xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2 <- read_xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2
test3 <- xml(test2)
test2 <- read_xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2$doc
test2$node
read_xlm
read_xml
?read_xml
test2 <- read_xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd", as_html = T)
test2 <- read_xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
as.data.frame(test2)
doc <- xmlTreeParse(test2, useInternalNodes = TRUE)
doc
xmlToDataFrame(doc)
test3 <- xmlToDataFrame(doc)
View(test3)
test3 <- xmlToDataFrame(test2)
library(shinyjs)
library(shinythemes)
library(shiny)
library(shinyBS)
library(shinyjs)
library(shiny)
library(shinythemes)
#### Challenger App ###
library(shiny)
library(shinyBS)
library(shinyjs)
library(shiny)
library(shinythemes)
ui <- bootstrapPage(theme = "simplex")
server <- function(input, output, session){}
shinyApp(ui = ui, server = server)
ui <- bootstrapPage(theme = "simplex",
headerPanel("Challenger", "Challenger title"))
server <- function(input, output, session){}
shinyApp(ui = ui, server = server)
ui <- bootstrapPage(theme = "simplex",
headerPanel(NULL, "Challenger title"))
server <- function(input, output, session){
session$StopApp
}
shinyApp(ui = ui, server = server)
?headerPanel
?tabsetPanel
ui <- bootstrapPage(theme = "simplex",
headerPanel(NULL, "Challenger title"),
mainPanel(tabsetPanel(
tabPanel("A", "First panel"),
tabPanel("B", "Second Panel"),
tabPanel("C", "Third"),
))
)
server <- function(input, output, session){
session$onSessionEnded(stopApp)
}
shinyApp(ui = ui, server = server)
ui <- bootstrapPage(theme = "simplex",
headerPanel(NULL, "Challenger title"),
mainPanel(tabsetPanel(
tabPanel("A", "First panel"),
tabPanel("B", "Second Panel"),
tabPanel("C", "Third")
))
)
server <- function(input, output, session){
session$onSessionEnded(stopApp)
}
shinyApp(ui = ui, server = server)
ui <- bootstrapPage(theme = "simplex",
headerPanel(HTML("<b style = 'font-size:40px;'>This is the Header</b>"), "Challenger title"),
mainPanel(tabsetPanel(
tabPanel("A", "First panel"),
tabPanel("B", "Second Panel"),
tabPanel("C", "Third")
))
)
server <- function(input, output, session){
session$onSessionEnded(stopApp)
}
shinyApp(ui = ui, server = server)
setwd("C:/Users/mbrackenrig/Documents/Assignment-2")
setwd("C:/Users/mbrackenrig/Documents/Assignment-2")
setwd("G:/Team Drives/STDS - Assignment 2 - 3MDL/Dataset/AirBnB")
files <- list.files()
files
for(i in 1:length(files)){
#Read file
temp <- read_csv(files[i])
#call the file by the name of the csv
assign(substr(files[i], start = 0, stop = nchar(files[i])-4),temp)
#remove the temp file name
rm(temp)
}
library(readr)
for(i in 1:length(files)){
#Read file
temp <- read_csv(files[i])
#call the file by the name of the csv
assign(substr(files[i], start = 0, stop = nchar(files[i])-4),temp)
#remove the temp file name
rm(temp)
}
for(i in 1:length(files)){
#Read file
if(grepl(pattern = ".csv",x = files[i])==T){
temp <- read_csv(files[i])
#call the file by the name of the csv
assign(substr(files[i], start = 0, stop = nchar(files[i])-4),temp)
#remove the temp file name
rm(temp)  }
}
setwd("C:/Users/mbrackenrig/Documents/Assignment-2")
library(gmapsdistance)
library(doParallel)
detectCores()
registerDoParallel(cores = detectCores()-1)
Timedata <- unique(subset(listings, select = c("latitude", "longitude","id")))
View(`Opera House by Public Transport`)
grid <- expand.grid(destination = c("Sydney+Opera+House", "Luna+Park+Sydney","Bondi+Beach", "Manly+Beach","Three+Sisters", "Pokolbin+NSW"), mode = c("driving", "transit"))
Timedata <- merge(grid, Timedata) #take every combination of the grid and Timedata
View(listings)
Timedata <- unique(subset(listings, select = c("latitude", "longitude")))
unique(subset(listings, select = c("experiences_offered))
)
unique(subset(listings, select = c("experiences_offered)))
unique(subset(listings, select = c("experiences_offered")))
table(listings$experiences_offered)
View(listings)
boxplot(listings$cancellation_policy~listings$price)
boxplot(listings$price~listings$cancellation_policy)
boxplot(as.numeric(listings$price)~listings$cancellation_policy)
boxplot(listings$cancellation_policy~as.numeric(listings$price))
boxplot(as.factor(listings$cancellation_policy)~as.numeric(listings$price))
table(as.factor(listings$cancellation_policy),as.numeric(listings$price))
table(as.numeric(listings$price))
table(listings$price)
View(listings)
read_excel
?read_excel
??read_excel
stopImplicitCluster()
install.packages("tcltk\")
install.packages("tcltk")
version
library(tcltk)
Timedata[,sample(nrow(Timedata), 300)]
Timedata[sample(nrow(Timedata), 300),]
Timedata <- unique(subset(listings, select = c("latitude", "longitude","id")))
library(doParallel)
registerDoParallel(cores = detectCores()-1)
Timedata <- unique(subset(listings, select = c("latitude", "longitude","id")))
grid <- expand.grid(destination = c("Sydney+Opera+House", "Luna+Park+Sydney","Bondi+Beach", "Manly+Beach","Three+Sisters", "Pokolbin+NSW"), mode = c("driving", "transit"))
Timedata <- merge(grid, Timedata) #take every combination of the grid and Timedata
Timedata <- Timedata[sample(nrow(Timedata), 300),]
library(tcltk)
pb <- tkProgressBar(title = "progress bar", min = 0,
max = nrow(Timedata), width = 300)
Timedata <- Timedata[sample(nrow(Timedata), 100),]
library(tcltk)
pb <- tkProgressBar(title = "progress bar", min = 0,
max = nrow(Timedata), width = 300)
Total_Data <- foreach(i=1:nrow(Timedata)) %dopar% {
library(gmapsdistance)
#Dont steal my API
set.api.key('AIzaSyCuLT1mFH6bhajliIgj1BZ4Srbf26qKseM')
TimeTotal <-  gmapsdistance(origin =paste0(Timedata$latitude[i],"+",Timedata$longitude[i]),destination = Timedata$destination[i], departure = as.numeric(as.POSIXct("2018-05-21 12:00:00")),combinations = "all",mode = Timedata$mode[i], shape = "wide")
setTkProgressBar(pb, i, label=paste( round(i/total*100, 0),
"% done"))
}
close(pb)
Total_Data <- foreach(i=1:nrow(Timedata)) %dopar% {
library(gmapsdistance)
library(tcltk)
#Dont steal my API
set.api.key('AIzaSyCuLT1mFH6bhajliIgj1BZ4Srbf26qKseM')
TimeTotal <-  gmapsdistance(origin =paste0(Timedata$latitude[i],"+",Timedata$longitude[i]),destination = Timedata$destination[i], departure = as.numeric(as.POSIXct("2018-05-21 12:00:00")),combinations = "all",mode = Timedata$mode[i], shape = "wide")
setTkProgressBar(pb, i, label=paste( round(i/total*100, 0),
"% done"))
}
Total_Data <- foreach(i=1:nrow(Timedata)) %dopar% {
library(gmapsdistance)
library(tcltk)
#Dont steal my API
set.api.key('AIzaSyCuLT1mFH6bhajliIgj1BZ4Srbf26qKseM')
TimeTotal <-  gmapsdistance(origin =paste0(Timedata$latitude[i],"+",Timedata$longitude[i]),destination = Timedata$destination[i], departure = as.numeric(as.POSIXct("2018-05-21 12:00:00")),combinations = "all",mode = Timedata$mode[i], shape = "wide")
setTkProgressBar(pb, i, label=paste( round(i, 0),
"% done"))
}
stopImplicitCluster()
hist(listings$reviews_per_month)
summary(listings$reviews_per_month)
table(listings$property_type)
summary(listings$reviews_per_month)
