shiny::runApp('Stateplus Distance Matrix')
runApp('Stateplus Distance Matrix')
runApp('Stateplus Distance Matrix')
runApp('Stateplus Distance Matrix')
library(Caret)
library(caret)
?trainControl()
data <- mtcars
data$vs <- as.factor(data$vs)
sample(x = round(nrow(data)*0.7), nrow(data))
sample(nrow(data), round(nrow(data)*0.7),  replace = F)
gbmTrain <- sample(nrow(data), round(nrow(data)*0.7),  replace = F)
gbmTrain <- data[,sample(nrow(data), round(nrow(data)*0.7),  replace = F)]
gbmTrain <- data[sample(nrow(data), round(nrow(data)*0.7),  replace = F),]
grid <- expand.grid(n.trees = c(1000,1500), interaction.depth=c(3:5), shrinkage=c(0.05,0.1,0.2), n.minobsinnode=c(20))
ctrl <- trainControl(method = "cv",number = 5, repeats = 5)
?train
?trainControl
gbmTrain <- data[sample(nrow(data), round(nrow(data)*0.7),  replace = F),]
#this creates the tuning grid, ensure you name the features the same as the hyper parameters
grid <- expand.grid(n.trees = c(1000,1500), interaction.depth=c(3:5), shrinkage=c(0.05,0.1,0.2), n.minobsinnode=c(20))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
###Optimise for the Testing Set
set.seed(124)
library(caret)
GBMModel <- train(vs~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid[3,],)
gbmTrain <- data[sample(nrow(data), round(nrow(data)*0.9),  replace = F),]
grid <- expand.grid(n.trees = c(1000,1500), interaction.depth=c(3:5), shrinkage=c(0.05,0.1,0.2), n.minobsinnode=c(20))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
set.seed(124)
library(caret)
GBMModel <- train(vs~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid[3,],)
?train
GBMModel <- train(vs~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid[3,])
data
data <- data
datasets::AirPassengers
??datasets::
??datasets
data <- bordeaux
library(ade4)
data <- bordeaux
data <- data(bordeaux)
data <- iris
data$vs <- as.factor(data$vs)
data <- iris
gbmTrain <- data[sample(nrow(data), round(nrow(data)*0.9),  replace = F),]
#this creates the tuning grid, ensure you name the features the same as the hyper parameters
grid <- expand.grid(n.trees = c(1000,1500), interaction.depth=c(3:5), shrinkage=c(0.05,0.1,0.2), n.minobsinnode=c(20))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
###Optimise for the Testing Set
set.seed(124)
library(caret)
GBMModel <- train(Species~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid[3,])
summary(GBMModel)
print(GBMModel)
grid[3,]
GBMModel <- train(Species~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid)
GBMModel <- train(Species~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid)
View(grid)
grid <- expand.grid(n.trees = c(1000), interaction.depth=c(3:4), shrinkage=c(0.05,0.1), n.minobsinnode=c(20))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
###Optimise for the Testing Set
set.seed(124)
library(caret)
GBMModel <- train(Species~.,data = gbmTrain,
method = "gbm", trControl = ctrl, tuneGrid = grid)
print(GBMModel)
?gbm
table(gbmTrain$Species)
confusionMatrix(GBMModel)
library(glmnet)
lassofit <- cv.glmnet(Species~.)
training <- model.matrix(~ ., data))
training <- model.matrix(~ ., data)
training <- model.matrix(~ ., subset(data, select = -c("Species")))
training <- model.matrix(~ ., subset(data, select = c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")))
fit <- cv.glmnet(x = training, y = data$Species, alpha = 1)
fit <- cv.glmnet(x = training, y = data$Petal.width, alpha = 1)
training <- model.matrix(~ ., subset(data, select = c("Sepal.Length","Sepal.Width","Petal.Length")))
fit <- cv.glmnet(x = training, y = data$Petal.width, alpha = 1)
fit <- cv.glmnet(x = training, y = data$Petal.Width, alpha = 1)
?cv.glmnet
fit
summary(fit)
plot(fit)
print(fit)
fit$lambda.min
fit$lambda.1se
coef(fit, s = fit$lambda.min)
fit$lambda.min
fit$lambda.1se
coef(fit, s = fit$lambda.1se)
?cv.glmnet
fit <- cv.glmnet(x = training, y = data$Petal.Width, alpha = 0)
print(fit)
coef(fit, s = fit$lambda.min)
??svm
svmmodel <- train(Species~.,data = gbmTrain,
method = "lssvmRadial", trControl = ctrl)
svmmodel <- train(Species~.,data = gbmTrain,
method = "lssvmRadial")
print(svmmodel)
grid <- expand.grid(size = c(2,3,4), decay = (0.05, 0.1, 0.15))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
grid <- expand.grid(size = c(2,3,4), decay = c(0.05, 0.1, 0.15))
nnetmodel <- train(Species~.,data = data,
method = "nnet",trControl = ctrl, tuneGrid = grid)
print(nnetmodel)
grid <- expand.grid(size = c(2,3,4,5), decay = c(0.01,0.05, 0.1, 0.15))
ctrl <- trainControl(method = "repeatedcv",number = 5, repeats = 5, allowParallel = T)
nnetmodel <- train(Species~.,data = data,
method = "nnet",trControl = ctrl, tuneGrid = grid)
print(nnetmodel)
?nnet
install.packages("RJDBC")
library(RJDBC)
install.packages("rJava")
library(RJDBC)
library(installr)
updater()
experiment <- expand.grid(
Withdraw = c("Yes", "No"),
Revers = c("Yes", "No"),
Health = c("Yes", "No"),
Profit = c("Yes", "No"),
Deferred = c("Yes", "No")
)
design<-caFactorialDesign(data=experiment,type="orthogonal")
library(conjoint)
design<-caFactorialDesign(data=experiment,type="orthogonal")
View(design)
design2<-caFactorialDesign(data=experiment,type="orthogonal",cards = 2)
View(design2)
?caFactorialDesign
print(cor(caEncodedDesign(design)))
install.packages(c("nycflights13", "gapminder", "Lahman"))
ggplot(data = mpg)
library(tidyverse)
ggplot(data = mpg)
install.packages("tidyverse")
library(tidyverse)
library(installr)
shiny::runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
runApp('G:/My Drive/Janus Analytics/Client Files/StatePlus/Planner_Optimisation_MB')
shiny::runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
library(boot)
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
install.packages("shinythemes")
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
runApp('planner-optimisation-tool')
700*1.2
install.packages("austres")
install.packages("astsa")
Q <- factor(cycle(austres)) # split into quarter factors
trend <- time(austres) - 1980 # center the time to make the results look better using 1980 as midway in the whole dataset
reg <- lm(log(austres) ~ 0 + trend + Q, na.action=NULL) # run the regression without intercept
summary(reg)
table(trend)
plot(trend)
plot(log(austres))
plot(Q)
plot(time(austres))
time(austres)
austres
plotaustres
plot(austres)
library(conjoint)
library(AlgDesign)
library(compiler)
??compiler
f <- function() {
a = 5
b = 6
a+b
}
f
f()
compile(f)
e <- compile(f)
e
fc(2)
f <- function(x) x+1
fc <- cmpfun(f)
fc(2)
View(fc)
oldJIT <- enableJIT(0)
# a simple example
f <- function(x) x+1
fc <- cmpfun(f)
fc(2)
e <- compile(f)
e()
e
?compile
eval(e)
f <- function() {
a = 5
b = 6
a+b
}
e <- compile(f)
eval(e)
e
e()
eval(e)
disassemble(e)
write(e, "e.dll")
write(e, "e")
cmpfile(e)
e
f <- eval(e)
f
f()
g <- eval(e)
g()
save(e)
save(e, file = "test")
save(e, file = "test.class")
e
mode(e)
model1<-lm(BMI~height + mass, data =filter(newStarwars,BMI<440))
newStarwars
data
data()
data(package = .packages(all.available = T))
library(tidyverse)
newStarwars
model1<-lm(BMI~height + mass, data =filter(newStarwars,BMI<440))
library(dplyr)
model1<-lm(BMI~height + mass, data =filter(newStarwars,BMI<440))
starwars %>% mutate(BMI:=mass/((height/100)^2)) -> newStarwars
ggplot(data = newStarwars, mapping = aes(x = mass, y = BMI)) + geom_point()
?filter
?select
model1<-lm(BMI~height + mass, data =filter(newStarwars,BMI<440))
model1
summary(model1)
predict(model1, data.frame(height = 60, mass = 35))
shiny::runApp('planner-consultation-tool')
titanicData <- read_csv("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv")
titanicData$id <- 1:nrow(titanicData)   # adding an id number to each row for tracking
titanic.train <- titanicData %>% dplyr::sample_frac(.75)
titanic.test  <- dplyr::anti_join(titanicData, titanic.train, by = 'id')
missmap(titanic.train, main = "Missing values vs observed")
library(Amelia)
install.packages("Amelia")
glm1 = glm(survived ~ pclass + sex, family=binomial(logit), data = titanic.train)
summary(glm1)
plot(glm1)
eq = function(x){1/(1+exp(-x))}
ggplot(data.frame(x=c(-20, 20)), aes(x=x)) + stat_function(fun=eq, geom="line") + xlab("X") + ylab("P(Y|X)")
predict(glm1,newdata = titanic.test[1,])
(prediction<-predict(glm1,newdata = data.frame(sex="male",pclass=3),type="response"))
(predicted<-predict(glm1,titanic.test,type='response'))
prediction <- ifelse(predicted > 0.5, 1, 0)
confusion  <- table(titanic.test$survived, prediction)
confusion
glm2 = glm(survived ~. , family = "binomial", data = titanic.train)
glm2 = glm(survived ~. , family = binomial(logit), data = titanic.train)
confusion
gpaData<- read_delim("http://onlinestatbook.com/2/case_studies/data/sat.txt",delim=" ")
mlm1 <- lm(univ_GPA ~ high_GPA + math_SAT + verb_SAT,data=gpaData)
summary(mlm1)
cor(gpaData)
awardData <- read_csv("https://stats.idre.ucla.edu/stat/data/poisson_sim.csv")
glimpse(awardData)
library(magrittr)
awardData %<>% mutate(id=as.factor(id),prog=as.factor(prog))
glimpse(awardData)
table(awardData$num_awards)
ggplot(awardData)+geom_bar(aes(x=num_awards))
glm.awards<-glm(num_awards~prog+math, awardData, family=poisson)
summary(glm.awards)
glm.awards<-glm(num_awards~prog+math, awardData, family=poisson)
glm1 = glm(survived ~ pclass + sex, family=binomial(logit), data = titanic.train)
plot(glm1$fitted.values)
hist(glm1$fitted.values)
summary(glm.awards)
hist(glm.awards$residuals)
hist(log(glm.awards$residuals))
hist(glm.awards$residuals)
summary(glm.awards$residuals)
summary(glm.awards$residuals+1)
sd(glm.awards$residuals+1)
sd(glm.awards$residuals)
predict(glm.awards,newdata = data.frame(prog=factor(2),math=54),type="response")
install.packages("AER")
??pir
?pir
library(jsonlite)
library(rjson)
test <- fromJSON("https://data.gov.au/api/3/action/package_show?id=70c2b2fe-2a32-450e-98dc-453fe4a02aae")
test <- fromJSON(file = "https://data.gov.au/api/3/action/package_show?id=70c2b2fe-2a32-450e-98dc-453fe4a02aae")
test
test$result
fromJSON(test$result)
library(XML)
test2 <- xml(x = "https://data.gov.au/dataset/location-of-centrelink-offices/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2
??xml
library(rvest)
test2 <- xml(x = "https://data.gov.au/dataset/location-of-centrelink-offices/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2 <- read_xml(x = "https://data.gov.au/dataset/location-of-centrelink-offices/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test$result
unlist(test)
test2 <- as.data.frame(unlist(test))
View(test2)
library(rvest)
test2 <- xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2 <- read_xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2
test3 <- xml(test2)
test2 <- read_xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
test2$doc
test2$node
read_xlm
read_xml
?read_xml
test2 <- read_xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd", as_html = T)
test2 <- read_xml(x = "https://data.gov.au/dataset/70c2b2fe-2a32-450e-98dc-453fe4a02aae/gmd")
as.data.frame(test2)
doc <- xmlTreeParse(test2, useInternalNodes = TRUE)
doc
xmlToDataFrame(doc)
test3 <- xmlToDataFrame(doc)
View(test3)
test3 <- xmlToDataFrame(test2)
library(shinyjs)
library(shinythemes)
library(shiny)
library(shinyBS)
library(shinyjs)
library(shiny)
library(shinythemes)
#### Challenger App ###
library(shiny)
library(shinyBS)
library(shinyjs)
library(shiny)
library(shinythemes)
ui <- bootstrapPage(theme = "simplex")
server <- function(input, output, session){}
shinyApp(ui = ui, server = server)
ui <- bootstrapPage(theme = "simplex",
headerPanel("Challenger", "Challenger title"))
server <- function(input, output, session){}
shinyApp(ui = ui, server = server)
ui <- bootstrapPage(theme = "simplex",
headerPanel(NULL, "Challenger title"))
server <- function(input, output, session){
session$StopApp
}
shinyApp(ui = ui, server = server)
?headerPanel
?tabsetPanel
ui <- bootstrapPage(theme = "simplex",
headerPanel(NULL, "Challenger title"),
mainPanel(tabsetPanel(
tabPanel("A", "First panel"),
tabPanel("B", "Second Panel"),
tabPanel("C", "Third"),
))
)
server <- function(input, output, session){
session$onSessionEnded(stopApp)
}
shinyApp(ui = ui, server = server)
ui <- bootstrapPage(theme = "simplex",
headerPanel(NULL, "Challenger title"),
mainPanel(tabsetPanel(
tabPanel("A", "First panel"),
tabPanel("B", "Second Panel"),
tabPanel("C", "Third")
))
)
server <- function(input, output, session){
session$onSessionEnded(stopApp)
}
shinyApp(ui = ui, server = server)
ui <- bootstrapPage(theme = "simplex",
headerPanel(HTML("<b style = 'font-size:40px;'>This is the Header</b>"), "Challenger title"),
mainPanel(tabsetPanel(
tabPanel("A", "First panel"),
tabPanel("B", "Second Panel"),
tabPanel("C", "Third")
))
)
server <- function(input, output, session){
session$onSessionEnded(stopApp)
}
shinyApp(ui = ui, server = server)
setwd("C:/Users/mbrackenrig/Documents/Assignment-2")
#Pull in data
source("Preprocessing/ReadAirbnb.r")
setwd("C:/Users/mbrackenrig/Documents/Assignment-2")
#Clean data - Put it in correct formate, etc..
source("Preprocessing/Cleaning.r")
Model <- merge(listings, Host_Verifications, by = "id")
Model <- merge(Model, `Opera House by Public Transport`, by = "id")
Model <- merge(Model, Amenities, by = "id")
library(gmapsdistance)
#The gmaps function is as follows
#gmapsdistance(origin, destination, combinations, mode, key,
#shape, avoid, departure, dep_date, dep_time,
#traffic_model, arrival, arr_date, arr_time)
#Register do parallel so it is faster
library(doParallel)
registerDoParallel(cores = detectCores()-1)
#get the unique listing (note they are all unique)
Timedata1 <- unique(subset(listings, select = c("latitude", "longitude","id")))
#Test
#gmapsdistance(origin =paste0("-33.8","+,+","151"),destination = 'Sydney+Opera+House', departure = as.numeric(as.POSIXct("2018-04-21 12:00:00")),combinations = "all",mode = "transit", shape = "wide")
####Public Transport to Opera House####
#Opera_Public_Data <- foreach(i=1:nrow(Timedata)) %dopar% {
#  library(gmapsdistance)
#Dont steal my API
#  set.api.key('YOU MUST SEt THE API KEY!!!')
#  OperaTimePublic <- gmapsdistance(origin =paste0(Timedata$latitude[i],"+",Timedata$longitude[i]),destination = 'Sydney+Opera+House', departure = as.numeric(as.POSIXct("2018-04-21 12:00:00")),combinations = "all",mode = "transit", shape = "wide")
#}
#Write to DF
#Opera_Public <- as.data.frame(matrix(unlist(Opera_Public_Data), ncol = 3,byrow = TRUE))
#Opera_Public <- cbind(Opera_Public, listings$id)
#Rename for Cleaning
#colnames(Opera_Public) <- c("Time", "Distance", "Status", "id")
#Change columns to correct format
#Time in Seconds
#Opera_Public$Time <- as.numeric(as.character(Opera_Public$Time))
#Distance in Meters
#Opera_Public$Distance <- as.numeric(as.character(Opera_Public$Distance))
#write_csv(Opera_Public, "G:/Team Drives/STDS - Assignment 2 - 3MDL/Dataset/AirBnB/Opera House by Public Transport.csv")
####Define Grid####
# important places to go in sydeny are as follows:
# Opera House and Harbour Bridge
# Luna Park
# Bondi Beach
# Manly Beach
# Blue mountains (three sisters)
# Pokolbin (hunter valley)
#We will make the assumption that participants will either want to travel by car or by public transport, not by walking or cycling
#The date and time will be determined on the weekend
#Business Travel
# Convention centre
# Macquarie Park
# Bella Vista
# Paramatta
# Alexandria
# UNSW
# UTS
grid <- expand.grid(destination = c("Sydney+Opera+House","Bondi+Beach", "Manly+Beach","Three+Sisters", "Pokolbin+NSW"), mode = c( "transit"))
grid <- subset(grid, grid$destination!="Sydney+Opera+House"|grid$mode!="transit")
Timedata <- merge(grid, Timedata1) #take every combination of the grid and Timedata
Total_Data<-  foreach(i=1:10) %dopar% {
library(gmapsdistance)
#Dont steal my API
set.api.key('AIzaSyCuLT1mFH6bhajliIgj1BZ4Srbf26qKseM')
TimeTotal <-  gmapsdistance(origin =paste0(Timedata$latitude[i],"+",Timedata$longitude[i]),destination = Timedata$destination[i], departure = as.numeric(as.POSIXct("2018-05-21 12:00:00")),combinations = "all",mode = Timedata$mode[i], shape = "wide")
}
Total_Data_DF <- as.data.frame(matrix(unlist(Total_Data), ncol = 3,byrow = TRUE)) #turn to tidyform
Total_Data_DF_Final <- cbind(Total_Data_DF, Timedata) #Match with the other stuff
Total_Data_DF_Final <- cbind(Total_Data_DF, Timedata[,1:10]) #Match with the other stuff
Total_Data_DF_Final <- cbind(Total_Data_DF, Timedata[1:101:10,]) #Match with the other stuff
Total_Data_DF_Final <- cbind(Total_Data_DF, Timedata[1:10,]) #Match with the other stuff
colnames(Total_Data_DF_Final[,1:3]) <- c("Time", "Distance", "Status")
colnames(Total_Data_DF_Final) <- c("Time", "Distance", "Status")
Total_Data_DF_Final <- cbind(Total_Data_DF, Timedata) #Match with the other stuff
Total_Data_DF_Final <- cbind(Total_Data_DF, Timedata[1:10,]) #Match with the other stuff
colnames(Total_Data_DF_Final) <- c("Time", "Distance", "Status",colnames(Total_Data_DF_Final[,4:8]) )
Opera_Public$Time <- as.numeric(as.character(Opera_Public$Time))
